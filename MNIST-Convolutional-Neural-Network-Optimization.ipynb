{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Import Necessary Libraries\n","This cell imports the required libraries for the project, including TensorFlow and NumPy."]},{"cell_type":"code","execution_count":2,"metadata":{"deletable":false,"editable":false,"id":"ZpztRwBouwYp","tags":["graded"]},"outputs":[],"source":["import os\n","import base64\n","import numpy as np\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{},"source":["### Load and Inspect MNIST Dataset\n","This cell loads the MNIST dataset and prints some basic information about the training data."]},{"cell_type":"code","execution_count":3,"metadata":{"deletable":false,"editable":false,"tags":["graded"]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/Users/dewminaimalsha/Downloads/data/mnist.npz'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m current_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m      4\u001b[0m data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/mnist.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m (training_images, training_labels), _ \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mmnist\u001b[38;5;241m.\u001b[39mload_data(path\u001b[38;5;241m=\u001b[39mdata_path)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_images is of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(training_images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining_labels is of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(training_labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m data_shape \u001b[38;5;241m=\u001b[39m training_images\u001b[38;5;241m.\u001b[39mshape\n","File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/datasets/mnist.py:60\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads the MNIST dataset.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03mThis is a dataset of 60,000 28x28 grayscale images of the 10 digits,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    https://creativecommons.org/licenses/by-sa/3.0/)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m origin_folder \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://storage.googleapis.com/tensorflow/tf-keras-datasets/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 60\u001b[0m path \u001b[38;5;241m=\u001b[39m get_file(\n\u001b[1;32m     61\u001b[0m     fname\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m     62\u001b[0m     origin\u001b[38;5;241m=\u001b[39morigin_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m     file_hash\u001b[38;5;241m=\u001b[39m(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m     ),\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(path, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     68\u001b[0m     x_train, y_train \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_train\u001b[39m\u001b[38;5;124m\"\u001b[39m], f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_train\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/utils/file_utils.py:291\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m         urlretrieve(origin, fpath, DLProgbar())\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n","File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/urllib/request.py:250\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Handle temporary file setup.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m--> 250\u001b[0m     tfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     tfp \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/dewminaimalsha/Downloads/data/mnist.npz'"]}],"source":["# Get current working directory\n","current_dir = os.getcwd()\n","\n","# Append data/mnist.npz to the previous path to get the full path\n","data_path = os.path.join(current_dir, \"data/mnist.npz\")\n","\n","# Load data (discard test set)\n","(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n","\n","print(f\"training_images is of type {type(training_images)}.\\ntraining_labels is of type {type(training_labels)}\\n\")\n","\n","# Inspect shape of the data\n","data_shape = training_images.shape\n","\n","print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"]},{"cell_type":"markdown","metadata":{},"source":["### Define a Function to Reshape and Normalize Images\n","This function reshapes the MNIST images to fit the input shape expected by the model and normalizes the pixel values."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"tags":["graded"]},"outputs":[],"source":["# reshape_and_normalize\n","\n","def reshape_and_normalize(images):\n","    \"\"\"Reshapes the array of images and normalizes pixel values.\n","\n","    Args:\n","        images (numpy.ndarray): The images encoded as numpy arrays\n","\n","    Returns:\n","        numpy.ndarray: The reshaped and normalized images.\n","    \"\"\"\n","\n","    # Reshape the images to add an extra dimension (at the right-most side of the array)\n","    images = images.reshape(-1, 28, 28, 1)\n","    \n","    # Normalize pixel values\n","    images = images / 255.0\n","\n","    return images"]},{"cell_type":"markdown","metadata":{},"source":["### Load and Inspect MNIST Dataset\n","This cell loads the MNIST dataset and prints some basic information about the training data."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false,"tags":["graded"]},"outputs":[{"name":"stdout","output_type":"stream","text":["Maximum pixel value after normalization: 1.0\n","\n","Shape of training set after reshaping: (60000, 28, 28, 1)\n","\n","Shape of one image after reshaping: (28, 28, 1)\n"]}],"source":["# Reload the images in case you run this cell multiple times\n","(training_images, _), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n","\n","training_images = reshape_and_normalize(training_images)\n","\n","print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n","print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n","print(f\"Shape of one image after reshaping: {training_images[0].shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"tags":["graded"]},"outputs":[],"source":["# EarlyStoppingCallback\n","\n","# Remember to inherit from the correct class\n","class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        \n","        # Check if the accuracy is greater or equal to 0.995\n","        if logs.get('accuracy') >= 0.995:\n","                            \n","            # Stop training once the above condition is met\n","            self.model.stop_training = True\n","\n","            print(\"\\nReached 99.5% accuracy so cancelling training!\") "]},{"cell_type":"markdown","metadata":{},"source":["### Define the Convolutional Model\n","This cell defines a convolutional neural network (CNN) model using TensorFlow's Keras API."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"tags":["graded"]},"outputs":[],"source":["# convolutional_model\n","\n","def convolutional_model():\n","    \"\"\"Returns the compiled (but untrained) convolutional model.\n","\n","    Returns:\n","        tf.keras.Model: The model which should implement convolutions.\n","    \"\"\"\n","\n","    # Define the model\n","    model = tf.keras.models.Sequential([\n","        tf.keras.Input(shape=(28, 28, 1)),\n","        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n","        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(128, activation='relu'),\n","        tf.keras.layers.Dense(10, activation='softmax')\n","    ])\n","\n","    # Compile the model\n","    model.compile(\n","\t\toptimizer='adam',\n","\t\tloss='sparse_categorical_crossentropy',\n","\t\tmetrics=['accuracy']\n","\t)\n","          \n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["### Define the Convolutional Model\n","This cell defines a convolutional neural network (CNN) model using TensorFlow's Keras API."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[92mYour model has 693,962 total parameters and the reference is 1,000,000\u001b[92m. You are good to go!\n","\n","\u001b[92mYour model has 693,962 trainable parameters and the reference is 1,000,000\u001b[92m. You are good to go!\n"]}],"source":["# compiled but untrained model\n","model = convolutional_model()"]},{"cell_type":"markdown","metadata":{},"source":["### Train the Model\n","This cell trains the model using the training data for a specified number of epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"deletable":false,"editable":false},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 23ms/step - accuracy: 0.9117 - loss: 0.2975\n","Epoch 2/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 23ms/step - accuracy: 0.9838 - loss: 0.0571\n","Epoch 3/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.9910 - loss: 0.0289\n","Epoch 4/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.9937 - loss: 0.0194\n","Epoch 5/10\n","\u001b[1m 244/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - accuracy: 0.9950 - loss: 0.0127"]}],"source":["# Training model\n","training_history = model.fit(training_images, training_labels, epochs=10, callbacks=[EarlyStoppingCallback()])"]}],"metadata":{"grader_version":"1","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
